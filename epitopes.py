# -*- coding: utf-8 -*-
"""Copia de Epitopos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jBh9iwUTNM6GWNZs71kf31bt3vpk4yMC
"""

#@title Install libraries, import packages and define constants

# Installation of necessary libraries
!apt install libgraphviz-dev
!pip install -q biopython
!pip install python-docx
!pip install -q nglview
!pip install pygraphviz
!pip install py3Dmol

# Imports
from collections import defaultdict
import re
import py3Dmol  #Para visualizacion
from Bio.PDB import PDBParser
from Bio.PDB.SASA import ShrakeRupley   #Calcula el área de superficie accesible al solvente (SASA)
from sklearn.cluster import KMeans, AffinityPropagation, MeanShift, SpectralClustering, AgglomerativeClustering, FeatureAgglomeration, DBSCAN, OPTICS, Birch, BisectingKMeans#, GaussianMixture
import nglview as nv
from nglview.color import ColormakerRegistry
import seaborn as sns
import ipywidgets as widgets
from google.colab import output
import numpy as np
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import math
from docx import Document
from docx.shared import RGBColor
import pickle
import colorsys

# Constants
#La siguiente matriz se utiliza para puntuar la similitud entre aminoácidos en secuencias proteicas
matrix = """
*  A  R  N  D  C  Q  E  G  H  I  L  K  M  F  P  S  T  W  Y  V  B  Z  X  *
A  4 -1 -2 -2  0 -1 -1  0 -2 -1 -1 -1 -1 -2 -1  1  0 -3 -2  0 -2 -1  0 -4
R -1  5  0 -2 -3  1  0 -2  0 -3 -2  2 -1 -3 -2 -1 -1 -3 -2 -3 -1  0 -1 -4
N -2  0  6  1 -3  0  0  0  1 -3 -3  0 -2 -3 -2  1  0 -4 -2 -3  3  0 -1 -4
D -2 -2  1  6 -3  0  2 -1 -1 -3 -4 -1 -3 -3 -1  0 -1 -4 -3 -3  4  1 -1 -4
C  0 -3 -3 -3  9 -3 -4 -3 -3 -1 -1 -3 -1 -2 -3 -1 -1 -2 -2 -1 -3 -3 -2 -4
Q -1  1  0  0 -3  5  2 -2  0 -3 -2  1  0 -3 -1  0 -1 -2 -1 -2  0  3 -1 -4
E -1  0  0  2 -4  2  5 -2  0 -3 -3  1 -2 -3 -1  0 -1 -3 -2 -2  1  4 -1 -4
G  0 -2  0 -1 -3 -2 -2  6 -2 -4 -4 -2 -3 -3 -2  0 -2 -2 -3 -3 -1 -2 -1 -4
H -2  0  1 -1 -3  0  0 -2  8 -3 -3 -1 -2 -1 -2 -1 -2 -2  2 -3  0  0 -1 -4
I -1 -3 -3 -3 -1 -3 -3 -4 -3  4  2 -3  1  0 -3 -2 -1 -3 -1  3 -3 -3 -1 -4
L -1 -2 -3 -4 -1 -2 -3 -4 -3  2  4 -2  2  0 -3 -2 -1 -2 -1  1 -4 -3 -1 -4
K -1  2  0 -1 -3  1  1 -2 -1 -3 -2  5 -1 -3 -1  0 -1 -3 -2 -2  0  1 -1 -4
M -1 -1 -2 -3 -1  0 -2 -3 -2  1  2 -1  5  0 -2 -1 -1 -1 -1  1 -3 -1 -1 -4
F -2 -3 -3 -3 -2 -3 -3 -3 -1  0  0 -3  0  6 -4 -2 -2  1  3 -1 -3 -3 -1 -4
P -1 -2 -2 -1 -3 -1 -1 -2 -2 -3 -3 -1 -2 -4  7 -1 -1 -4 -3 -2 -2 -1 -2 -4
S  1 -1  1  0 -1  0  0  0 -1 -2 -2  0 -1 -2 -1  4  1 -3 -2 -2  0  0  0 -4
T  0 -1  0 -1 -1 -1 -1 -2 -2 -1 -1 -1 -1 -2 -1  1  5 -2 -2  0 -1 -1  0 -4
W -3 -3 -4 -4 -2 -2 -3 -2 -2 -3 -2 -3 -1  1 -4 -3 -2 11  2 -3 -4 -3 -2 -4
Y -2 -2 -2 -3 -2 -1 -2 -3  2 -1 -1 -2 -1  3 -3 -2 -2  2  7 -1 -3 -2 -1 -4
V  0 -3 -3 -3 -1 -2 -2 -3 -3  3  1 -2  1 -1 -2 -2  0 -3 -1  4 -3 -2 -1 -4
B -2 -1  3  4 -3  0  1 -1  0 -3 -4  0 -3 -3 -2  0 -1 -4 -3 -3  4  1 -1 -4
Z -1  0  0  1 -3  3  4 -2  0 -3 -3  1 -1 -3 -1  0 -1 -3 -2 -2  1  4 -1 -4
X  0 -1 -1 -1 -2 -1 -1 -1 -1 -1 -1 -1 -1 -1 -2  0  0 -2 -1 -1 -1 -1 -1 -4
* -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4  1"""
matrix = list(map(lambda x: re.sub('\s+', ' ', x).split(), matrix.split('\n')))[1:]
table = defaultdict(lambda: float('-inf'))
for i, s in enumerate(matrix[0][1:-1]):
    for j, o in enumerate(matrix[0][1:-1]):
        table[s, o] = float(matrix[i+1][j+1])
        table[o, s] = float(matrix[i+1][j+1])

#Conversión de los nombres completos de los aminoácidos (en formato de tres letras, extraída del archivo PDB) y sus equivalentes en formato de una letra
codes = {
    'ala': 'A',
    'arg': 'R',
    'asn': 'N',
    'asp': 'D',
    'asx': 'B',
    'cys': 'C',
    'glu': 'E',
    'gln': 'Q',
    'glx': 'Z',
    'gly': 'G',
    'his': 'H',
    'ile': 'I',
    'leu': 'L',
    'lys': 'K',
    'met': 'M',
    'phe': 'F',
    'pro': 'P',
    'ser': 'S',
    'thr': 'T',
    'trp': 'W',
    'tyr': 'Y',
    'val': 'V'
}

#Variable que se utilizará mas tarde para almacenar los puntos donde la concentración de epítopos es alta
centroid_positions = []


#Esta clase se utiliza para poder realizar operaciones con puntos en 3d (define las operaciones basicas como la suma, pero para tres componentes)
class Point:
    def __init__(self, x=0, y=0, z=0):
        self.x = x
        self.y = y
        self.z = z

    def __add__(self, other):
        return Point(self.x + other.x, self.y + other.y, self.z + other.z)

    def __sub__(self, other):
        return Point(self.x - other.x, self.y - other.y, self.z - other.z)

    def __floordiv__(self, n):
        return Point(self.x // n, self.y // n, self.z // n)

    def __truediv__(self, n):
        return Point(self.x / n, self.y / n, self.z / n)

    def size(self):
        return abs(self.x) + abs(self.y) + abs(self.z)

#@title Parameters

epitopes_db_file = 'epitope_20250130.xlsx' #@param {type:"string"}
structure_file = 'Klebsiella pneumoniae.pdb' #@param {type:"string"}
result_file = 'result.xlsx' #@param {type:"string"}
centroid_positions = "" # @param {type:"string"}
#@markdown &nbsp;&nbsp;&nbsp;&nbsp;*(Comma separated values)*
threshold = 0.8 #@param {type:"number"}
sasa_threshold = 0.3 #@param {type:"number"}
interp_threshold = 0.3 #@param {type:"number"}
epitope_min_size = 7 #@param {type:"number"}
n = 3 #@param {type:"number"}

if centroid_positions:
    centroid_positions = list(map(lambda x: int(x)-1, centroid_positions.split(",")))

p = PDBParser(QUIET=1)
struct = p.get_structure("PROT", structure_file)
sequence = ''.join(map(lambda x: codes[x.resname.lower()], struct.get_residues()))

"""## Setup"""

#Se implementa un autómata para representar los epítopos como secuencias de transiciones. Cada nodo representa un aminoácido en la secuencia
class Node:
    def __init__(self):
        self.transitions = defaultdict(Node)
        self.final = False
        self.label = None
        #Ahora se almacenan los valores mínimo y máximo de las puntaciones asociadas a las secuencias que pasan por este nodo.
        #Estos se calculan con la matriz BLOSUM y son para filtrar secuencias que no cumplen ciertos umbrales
        self.min_score = float('inf')
        self.max_score = 0

    #Genera una representación visual del autómata usando NetworkX.
    def plot(self):
        G = nx.DiGraph()
        self._plot(G, 0)

        pos = nx.nx_agraph.graphviz_layout(G, prog="dot", args="")  # Graphviz con el programa dot organiza nodos y transiciones de forma jerárquica.
        nx.draw(G, pos, node_size=5)                                # Dibuja el grafo con los nodos y las conexiones
        nx.draw_networkx_edge_labels(G, pos, edge_labels=nx.get_edge_attributes(G,'label')) #Añade etiquetas a las aristas
        plt.show()                                                  # Muestra el grafo

    #Constuye todo el grafo desde el nodo inicial de forma recursiva
    def _plot(self, G, i):
        G.add_node(i)                           # Añade el nodo actual i al grafo G
        last = i
        for k, v in self.transitions.items():   # k representa la etiqueta asociada a la transición y v el nodo destino
            last = last+1                       # Genera un nuevo identificador para el siguiente nodo
            G.add_edge(i, last, label=k)        # Crea una arista entre i y el nodo destino last, etiquetándola con k
            last = v._plot(G, last)             # Llama recursivamente al método _plot para explorar el nodo destino v y añadir sus transiciones al grafo
        return last

df = pd.read_excel(epitopes_db_file, skiprows=[0])

"""## Dictionary automaton with BLOSUM"""

def epitope_score(epitope):
    return sum(table[e, e] for e in epitope)      #Aqui se calcula la suma de todos los aminoacidos que hay en un epítopo (vamos sumando la similitud de un aminoacido consigo mismo)

p = PDBParser(QUIET=1)   #Llama a Biopython (para leer y analizar archivos PDB que contienen las coordenadas atómicas de estructuras proteicas), QUIET=1 suprime mensajes de advertencia
struct = p.get_structure("PROT", structure_file)  #Cargar la estructura desde el archivo PDB structure_file
sr = ShrakeRupley()                               #calcular el área de superficie accesible al solvente SASA (Valores altos indican que el residuo es accesible)
sr.compute(struct, level="R")                     #Calcula SASA para cada residuo (aminoácido) de struct
residues = list(struct.get_residues())            #Extrae los residuos de la estructura

# En este fragmento construimos el autómata para representar los epítopos como secuencias de aminoácidos
# Cada epítopo del archivo df se inserta en el autómata (cada nodo corresponde a un aminoácido de la secuencia)
dfa = Node()                              #dfa es el nodo raíz del autómata, y llama a Node, la clase definida previamente
for index, row in df.iterrows():          #Iteramos sobre las filas del archivo de epítopos (cada fila representa un epítopo)
    #Si el nombre del epítopo no consiste únicamente en letras mayúsculas o la longitud del epítopo es menor al mínimo especificado, salta a la siguiente iteración (epítopo no válido)
    if not re.match(r'^[A-Z]+$', row['Name']) or len(row['Name']) < epitope_min_size:
        continue

    score = epitope_score(row['Name'])    # Se calcula la puntuacion del epítopo usando la matriz BLOSUM
    node = dfa                            # Se inicializa el automata
    #min_score es infinito y max_score es 0. El min_score/max_score* que se almacena para cada nodo (aminoácido) es el score del residuo
    node.min_score = min(node.min_score, score)
    node.max_score = max(node.max_score, score)
    for s in row['Name']:                 #Iterar sobre los aminoácidos del epítopo
        node = node.transitions[s]        #node actualiza su valor al nodo correspondiente
        # Ahora actualiza los scores en el nodo correspondiente
        node.min_score = min(node.min_score, score)
        node.max_score = max(node.max_score, score)
    node.final = True                     #Se actualiza el nodo actual como un estado final
    node.label = row['Name']              # Se asocia el epítopo completo como etiqueta del nodo final

epitopes = [[] for _ in range(len(sequence))]     #inicializamos epitopes, que es una lista de listas que almacenará los epítopos encontrados en cada posición de la secuencia de la proteína

states = []                                       #states almacena los estados actuales del autómata
for i, residue in enumerate(residues):            #Iteramos sobre los residuos de la proteína
    s = codes[residue.resname.lower()]            #Traduce el nombre en tres letras al formato de una sola letra
    states.append((dfa, i, 0, 0))                 # Añade el estado inicial (dfa: Nodo raíz, i: Índice del residuo actual, 0: Longitud inicial de la subsecuencia, 0: Diferencia inicial en scores)

    _states = []
    for (node, start, length, diff) in states:    #Recorre los estados del autómata (node: Nodo actual, start: Posición inicial de la subsecuencia, length: Longitud actual, diff: Diferencia acumulada)
        #Si el max_score sumado a la diferencia es menor que el node.min_score * threshold, descarta este estado
        if node.max_score + diff < node.min_score * threshold:
            continue
        #Si el nodo es final y el score acumulado supera el umbral, añade el epítopo (añadimos el nombre del último nodo, que habia tomado el nombre del epítopo)
        if node.final and (node.min_score + diff >= node.min_score * threshold):
            epitopes[start].append((node.label, diff))
        #Se exploran todas las posibles transiciones desde el nodo actual
        for x in node.transitions:
            _states.append((node.transitions[x], start, length+1, diff - table[s, s] + table[s, x]))
    states = _states

found = []
for start, l in enumerate(epitopes):
    for epitope, diff in l:
        found.append((start, epitope, diff))    # Se almacena cada epítopo encontrado junto con su posición de inicio y su diferencia de puntuacion

atoms = [list(r.get_atoms()) for r in residues]       #lista de listas, donde cada sublista contiene los átomos de un residuo.
positions = [sum(map(lambda a: Point(*a.coord), l), Point()) / len(l) for l in atoms]   #lista de objetos Point que representa la posición promedio de un residuo en 3d.

histogram = [0] * len(sequence)                       # Aqui se guarda el número de epitopos en cada posición

# Iteramos sobre la lista de epítopos identificados, donde cada elemento es una tupla (start, epitope, diff)
for start, epitope, diff in found:
    #Iteramos sobre los índices en la secuencia que corresponden al epítopo
    for i in range(start, start + len(epitope)):
        if (epitope_score(epitope) + diff) > 0:
            histogram[i] += 1                       #Si el puntaje ajustado del epítopo es positivo, incrementa el contador en el histograma para la posición i (un residuo puede pertenecer a varios epitopos)

sasa = [residue.sasa for residue in residues]         #Obtenemos el área de superficie accesible solvente de cada residuo

"""## Save / Load checkpoint"""

# Guardamos los datos intermedios de la ejecución en el archivo binario checkpoint.pickle.
# Esto optimiza el flujo de trabajo al permitir reanudar el análisis en un punto avanzado sin necesidad de volver a ejecutar cálculos previos
with open('checkpoint.pickle', 'wb') as f:
    pickle.dump({'sasa': sasa, 'histogram': histogram, 'positions': positions, 'residues': residues}, f)

# Aqui recuperamos los datos previamente guardados en checkpoint.pickle y los asignamos a las variables sasa, histogram, positions y residues para que puedan ser reutilizados
with open('checkpoint.pickle', 'rb') as f:
    e = pickle.load(f)
    sasa = e['sasa']
    histogram = e['histogram']
    positions = e['positions']
    residues = e['residues']

"""## Get score"""

# Este fragmento de código identifica las posiciones clave (centroides) en la secuencia de la proteína a partir del histograma de epítopos
if len(centroid_positions) == 0:
    #m = 0
    #for i in range(len(sequence)):
    #    if histogram[i] > m:
    #        m = histogram[i]
    #        centroid_positions = [i]
    #    elif histogram[i] == m:
    #        centroid_positions.append(i)
    #centroids = [centroid_positions[0]]
    #for c in centroid_positions:
    #    if c == centroids[-1] +1:
    #        centroids[-1] = c
    #    else:
    #        centroids.append(c)
    #centroid_positions = centroids

    centroid_positions =  []                  #Inicializar centroid_positions como lista vacía

    h = [0] + histogram + [0]                 #Agrega un 0 al principio y otro al final para que los picos en los bordes sean considerados
    #Recorre todos los índices del histograma y verifica si el valor actual h[i] es un pico local (hay mas concentración de epitopos que en sus vecinos)
    for i in range(1, len(sequence)+1):
        if h[i-1] <= h[i] and h[i] > h[i+1]:
            centroid_positions.append(i-1)    # La posición correspondiente (i-1) se añade a centroid_positions

#Lanza un error si no se detectaron picos en el histograma
if len(centroid_positions) == 0:
    raise ValueError("NO EPITOPES FOUND")

#Calculamos la distancia mínima entre cada residuo y los centroides detectados
dist = [min((positions[cp] - p).size() for cp in centroid_positions) for p in positions]

# Graficas no normalizadas (no las necesitamos)
# Primero creamos una figura con tres subgráficos (subplots) apilados verticalmente
#fig, axs = plt.subplots(3, sharex=True, sharey=False)

# Primer subgráfico: Concentración de epítopos
#axs[0].title.set_text('Epitopes concentration')  # Establecer título del gráfico
#axs[0].bar(range(len(histogram)), histogram)  # Graficar el histograma de epítopos como un gráfico de barras
#for x in centroid_positions:  # Dibujar líneas verticales en las posiciones de los centroides
#    axs[0].axvline(x=x, color='tab:purple')  # Línea morada para destacar los centroides

# Segundo subgráfico: Superficie accesible al solvente (SASA)
#axs[1].title.set_text('Solvent-accessible surface area')  # Establecer título del gráfico
#axs[1].bar(range(len(sasa)), sasa, color='tab:orange')  # Graficar los valores SASA como un gráfico de barras
#axs[1].axhline(y=max(sasa) * sasa_threshold, color='r', linestyle='-')  # Línea horizontal roja en el umbral de SASA
#fig.tight_layout()  # Ajustar el diseño para evitar solapamientos entre gráficos

# Tercer subgráfico: Distancia a los centroides
#axs[2].title.set_text('Centroid distance')  # Establecer título del gráfico
#axs[2].bar(range(len(dist)), dist, color='tab:green')  # Graficar las distancias como un gráfico de barras
#for x in centroid_positions:  # Dibujar líneas verticales en las posiciones de los centroides
#    axs[2].axvline(x=x, color='tab:purple')  # Línea morada para destacar los centroides
#fig.tight_layout()  # Ajustar el diseño nuevamente para los tres subgráficos

# Configurar las etiquetas del eje x
#plt.xticks(list(range(0, len(dist)+10, 10)), rotation=45, fontsize='x-small')  # Etiquetas con rotación y tamaño pequeño

# Mostrar la figura con los tres subgráficos
#plt.show()

# Ahora crearemos graficos para las metricas normalizadas, y además añadimos una puntuación como combinación ponderada de estas métricas
norm_max = math.log10(max(histogram))+1           # Es un factor de normalización para escalar los valores del histograma entre 0 y 1

# smooth_hist es la lista de valores normalizados, aplicando una función lambda (math.log10(x)+1)/norm_max a cada valor del histograma (las concentraciones altas de epítopos tienen valores mayores)
smooth_hist = list(map(lambda x: 0 if x == 0 else (math.log10(x)+1)/norm_max, histogram))
norm_dist = list(map(lambda x: x/max(dist), dist))    #norm_dist normaliza las distancias a los centroides aplicando una función lambda x/max(dist)
norm_sasa = list(map(lambda x: x/max(sasa), sasa))    #norm_sas normaliza las distancias a los centroides aplicando una función lambda x/max(sasa)

#Aquí definimos la función para calcular el score
def fscore(c, a, d):
    if a < sasa_threshold:
        return 0                                      # Si a es menor que el umbral, devuelve 0, ya que los residuos enterrados no se consideran epítopos probables
    return c * a * (1-d)
    # c: Da prioridad a zonas con alta concentración de epítopos.
    # a: Favorece epitopos más accesibles al solvente.
    # 1-d: Favorece epítopos más cercanos a los centroides (distancias menores)

score = [fscore(c, a, d) for c, a, d in zip(smooth_hist, norm_sasa, norm_dist)]  #Calculamos ese score para cada epitopo
norm_score = [s / max(score) for s in score]                                     #Normalizamos el score

# Aquí generamos otra vez una figura con cuatro subgráficos apilados verticalmente para visualizar diferentes métricas relacionadas con los epítopos, pero con métricas normalizadas
fig, axs = plt.subplots(4, sharex=True, sharey=False)

# Only epitopes
axs[0].title.set_text('Epitopes concentration normalized')
axs[0].bar(range(len(smooth_hist)), smooth_hist)

# Only SASA
axs[1].title.set_text('Solvent-accessible surface area normalized')
axs[1].bar(range(len(norm_sasa)), norm_sasa, color='tab:orange')
axs[1].axhline(y = sasa_threshold, color = 'r', linestyle = '-')
fig.tight_layout()

# Only distance
axs[2].title.set_text('Centroid distance normalized')
axs[2].bar(range(len(norm_dist)), norm_dist, color='tab:green')
fig.tight_layout()

# Only score
axs[3].title.set_text('Score')
axs[3].bar(range(len(norm_score)), norm_score, color='tab:purple')
fig.tight_layout()

plt.xticks(list(range(0, len(dist)+10, 10)), rotation=45, fontsize='x-small')

plt.show()

# Parámetros de interpolación lineal (1D)
if n < 0:
    n = 3                 # Número de vecinos más cercanos considerados a la izquierda y derecha
aten = 1               # Peso que disminuye exponencialmente con la distancia de los vecinos

# Función de interpolación lineal
def interp(i):
    # Calcula un valor interpolado para la posición i basado en sus vecinos
    return sum(
        norm_score[j] * aten ** abs(j-i)                          # Peso de cada vecino según su distancia
        for j in range(max(0, i-n), min(len(norm_score), i+n+1))  # Vecinos en el rango permitido
    )

# Calcular valores interpolados para cada posición en la secuencia
linear_interpolated = [interp(i) for i in range(len(norm_score))]

# Normalizar los valores interpolados para que estén entre 0 y 1
li_normalized = [i / max(linear_interpolated) for i in linear_interpolated]


# Parámetros de interpolación en 3D
m = n * 2 + 1         # Número de vecinos más cercanos considerados en 3d
aten3d = 1            # Peso que disminuye exponencialmente con la distancia en 3d

# Función de interpolación en 3d
def interp3d(pos):
    candidates = []   # Lista para almacenar las distancias y puntajes de los vecinos
    for i, p in enumerate(positions):
        # Calcular la distancia entre el residuo actual y todos los demás
        candidates.append(((pos-p).size(), norm_score[i]))
    # Ordenar los vecinos por distancia (menor a mayor)
    candidates = sorted(candidates)
    # Calcular el puntaje interpolado basado en los m vecinos más cercanos
    return sum(s * aten3d ** d for d, s in candidates[:m])

# Calcular valores interpolados para cada posición en 3d
interp_3d = [interp3d(p) for p in positions]

# Normalizar los valores interpolados en 3d para que estén entre 0 y 1
i3d_normalized = [i / max(interp_3d) for i in interp_3d]

# Crear gráficos para comparar la interpolación lineal y en 3d
fig, axs = plt.subplots()

# Primer subgráfico: Puntaje interpolado linealmente (no lo necesitamos)
# axs[0].title.set_text('Linearly interpolated score')          # Título del gráfico
# axs[0].bar(range(len(li_normalized)), li_normalized)          # Lo dibuja con los valores normalizados
# axs[0].axhline(y=interp_threshold, color='r', linestyle='-')  # Línea de umbral en rojo

# Segundo subgráfico: Puntaje interpolado en 3D
axs.title.set_text('3D interpolated score')                # Título del gráfico
axs.bar(range(len(i3d_normalized)), i3d_normalized)        # Dibuja con los valores normalizados ahora en 3d
axs.axhline(y=interp_threshold, color='r', linestyle='-')  # Línea de umbral en rojo

# Configurar etiquetas del eje x
plt.xticks(list(range(0, len(dist)+10, 10)), rotation=45, fontsize='x-small')  # Etiquetas del eje x rotadas y pequeñas

fig.tight_layout()

# Mostrar los gráficos
plt.show()

#final_score es el puntaje calculado para cada residuo de la proteína, considerando la proximidad espacial en 3D a otros residuos
final_score = i3d_normalized       # i3d_normalized (3D) or li_normalized (Lineal)

final_score = [x if x >= interp_threshold else 0 for x in final_score]

with open(structure_file) as ifile:
    system = "".join([x for x in ifile])

view = py3Dmol.view(width=400, height=300)
view.addModelsAsFrames(system)

first_residue_pos = None  # Variable para almacenar la primera posicion del residuo

i = 0
for line in system.split("\n"):
    split = line.split()
    if len(split) == 0 or split[0] != "ATOM":
        continue

    residue_position = int(split[5])  # Obtener el número de residuo en la PDB

    if first_residue_pos is None:  # Guardar solo el primero residuo encontrado
        first_residue_pos = residue_position

    score_index = residue_position - first_residue_pos

    if len(final_score) <= score_index:
      print("Nos pasamos del tamaño de las puntuaciones!!")
      break

    if final_score[score_index] > 0:
        color = int(255 * final_score[score_index])
        color = f"#{color:x}0000"
    else:
        color = "lightgrey"
    idx = int(split[1])

    view.setStyle({'model': -1, 'serial': i+1}, {'sphere':{'color': color}})#surface
    #view.setStyle({'model': -1, 'serial': i+1}, {"cartoon": {'color': color}})
    i += 1
view.zoomTo()
view.show()

def prRed(skk): print("\033[91m{}\033[00m".format(skk), end='')

i = 0
while i < len(sequence):
    if i % 10 == 0:
      print(i, end='')
      if i > 9:
        i += 1
      if i > 99:
        i += 1
    else:
      print(' ', end='')
    i += 1
print()

for i, r in enumerate(sequence):
    if final_score[i] > 0:
      prRed(r)
    else:
      print(r, end='')

"""## Export to word file"""

document = Document()                                   #Crea un documento de Word vacío

"""
N=len(centroid_positions)
palete = [(x*1.0/N, 0.5, 0.5) for x in range(len(centroid_positions))]
palete = list(map(lambda x: tuple(map(lambda x: int(x * 255), colorsys.hsv_to_rgb(*x))), palete))
"""
document.add_heading('Protein Epitope Analysis', level=1)
document.styles['Normal'].font.name = 'Courier New'     #Cambia el estilo de fuente a Courier New

document.add_heading('Below we can see 4 ways to highlight the residues that are part of epitopes and to differentiate them from each other.', level=2)

# Pasamos por cada residuo
document.add_heading('Epitope Details 1: the intensity of red in each sequence indicates a higher residue score.', level=2)
paragraph = document.add_paragraph()                    #Añade un nuevo párrafo
for i, r in enumerate(sequence):                        #Itera sobre cada residuo en la secuencia de la proteína
    if final_score[i] > 0:
        color = int(255 * final_score[i])               #Si el residuo es relevante, escala el final_score del residuo a un valor entre 0 y 255 para definir la intensidad del rojo
        run = paragraph.add_run(r)
        run.font.color.rgb = RGBColor(color, 0, 0)
    else:
        run = paragraph.add_run(r)                      #Si el residuo no es relevante, residuo en negro
        run.font.color.rgb = RGBColor(0, 0, 0)


#Igual que el anterior, pero ahora los residuos irrelevantes se colorean en gris claro en lugar de negro
document.add_heading('Epitope Details 2: the intensity of red in each sequence indicates a higher score, and gray indicates that the residue is irrelevant.', level=2)
paragraph = document.add_paragraph()
for i, r in enumerate(sequence):
    if final_score[i] > 0:
        color = int(255 * final_score[i])
        run = paragraph.add_run(r)
        run.font.color.rgb = RGBColor(color, 0, 0)
    else:
        run = paragraph.add_run(r)
        run.font.color.rgb = RGBColor(200, 200, 200)


#Igual que el anterior, pero ahora los residuos relevantes se colorean en rojo brillante constante , independientemente del score
document.add_heading('Epitope Details 3: color red in a sequence indicates that the residue is relevant (no intensity differentiation).', level=2)
paragraph = document.add_paragraph()
for i, r in enumerate(sequence):
    if final_score[i] > 0:
        run = paragraph.add_run(r)
        run.font.color.rgb = RGBColor(255, 0, 0)
    else:
        run = paragraph.add_run(r)
        run.font.color.rgb = RGBColor(0, 0, 0)


#Aqui agrupamos los residuos relevantes en grupos (distancia máxima entre dos residuos en el mismo grupo) basados en la cercanía espacial a los centroides
groups = [[] for _ in centroid_positions]         #De la lista que almacenará las posiciones 3d de los residuos de un grupo correspondiente a un centroide
for i, r in enumerate(sequence):
    #Si el score es positivo, encuentra el índice del centroide más cercano (mediante distancia euclidea) y añade la posición del residuo al grupo correspondiente a ese centroide
    if final_score[i] > 0:
        index = min( range(len(centroid_positions)), key=lambda j: (positions[centroid_positions[j]] - positions[i]).size())
        groups[index].append(positions[i])


#Aqui generaramos colores para cada grupo (colores entre 0 y 1)
N=sum(1 for i in groups if len(i))
palete = [(x*1.0/N, 0.5, 0.5) for x in range(len(centroid_positions))]
palete = list(map(lambda x: tuple(map(lambda x: int(x * 255), colorsys.hsv_to_rgb(*x))), palete))

#Aqui se añade cada residuo otra vez, pero ahora coloreando los residuos relevantes según el color asignado al grupo (palete[index])
document.add_heading('Epitope Details 4: the color of the sequence indicates the group the residue is part of.', level=2)
paragraph = document.add_paragraph()
groups = [[] for _ in centroid_positions]
for i, r in enumerate(sequence):
    if final_score[i] > 0:
        index = min( range(len(centroid_positions)), key=lambda j: (positions[centroid_positions[j]] - positions[i]).size())
        groups[index].append(positions[i])
        run = paragraph.add_run(r)
        run.font.color.rgb = RGBColor(*palete[index])
    else:
        run = paragraph.add_run(r)
        run.font.color.rgb = RGBColor(0, 0, 0)


# Aquí calculamos el diámetro de cada cluster
document.add_heading('The color of each group corresponds to that of the epitope above.', level=2)
document.add_heading('The diameter (ångstroms) of each group is calculated as the maximum Euclidean distance between the 3d positions of two residues.', level=2)
run = paragraph.add_run(f'\nClusters data:\n')
run.font.color.rgb = RGBColor(0, 0, 0)
index= -1
for n, group in enumerate(groups):      # Iteramos sobre cada grupo
    if len (group)==0:
      continue                          # Si no hay residuos asociados a ese grupo (esta vacio), pasamos al siguiente
    index += 1
    diameter = 0
    group_sequence = []                 #Creamos la lista para almacenar la secuencia de aminoacidos del grupo
    for n0, elem0 in enumerate(group):
        for n1, elem1 in enumerate(group):
            if n0 == n1:
                continue                                                  # Si solo hay un elemento, el diametro es 0
            diameter = max(diameter, (elem0 - elem1).size())              # Cogemos la distancia máxima entre dos residuos en el cluster (distancia euclidea entre las posiciones 3d de dos residuos)

    # Pasamos por cada residuo y comprobamos si pertenece al grupo
    for i, r in enumerate(sequence):
        if positions[i] in group:
            group_sequence.append(f'{r}({i+1})')                          # Incluimos la posicion junto al residuo
    group_sequence_str = ''.join(group_sequence)                          # Concatenamos la secuencia de residuos de cada grupo

    run = paragraph.add_run(f'Group {n+1}: {group_sequence_str}\n')       # Se añade un encabezado para cada cluster indicando su número y su color, y tambien los aminoacidos que lo forman
    run.font.color.rgb = RGBColor(*palete[index])
    run = paragraph.add_run(f'    Diameter: {diameter}\n\n')              # Se muestra el diámetro calculado para el cluster
    run.font.color.rgb = RGBColor(0, 0, 0)


document.add_heading('', level=2)
document.add_heading('Residue Details: each residue in the sequence appears accompanied by its position and its associated score.', level=2)
paragraph = document.add_paragraph()
for i, r in enumerate(sequence):
    run = paragraph.add_run(f'{(i+1):04} {r} {final_score[i]:.4f}\n')

#Aqui se registra y se escribe la fecha y hora
import datetime

doc_id = str(datetime.datetime.now()).replace("-", "").replace(":", "").replace(" ", "-")
doc_id = doc_id[:doc_id.index(".")]

document.save(f'result_{doc_id}.docx')

"""## Diagram"""

!pip install diagrams

from diagrams import Diagram, Cluster, Node
from diagrams.custom import Custom
from urllib.request import urlretrieve
from diagrams.elastic.beats import Filebeat
from diagrams.onprem.database import Postgresql
from diagrams.digitalocean.database import DbaasPrimaryStandbyMore
from diagrams.elastic.agent import Integrations

def custom_node(url, name):
    custom_node._index += 1
    urlretrieve(url, f'custom_icon_{custom_node._index}')
    return Custom(name, f'custom_icon_{custom_node._index}')

custom_node._index = 0

with Diagram("", direction='LR') as diag:
    with Cluster("Input data"):
        fasta_filebeat = Filebeat('FASTA sequence') # Changed variable name to fasta_filebeat
        db_filebeat = DbaasPrimaryStandbyMore('Epitopes DB') # Changed variable name to db_filebeat
        centroid_filebeat = Filebeat('Centroid') # Changed variable name to centroid_filebeat

    deepmind = Node("AlphaFold")  # Se reemplaza custom_node por Node
    da = Integrations('Automaton')
    sasa_calc = Integrations('Shrake–Rupley algorithm')
    distance_calc = Integrations('Distance calculation')
    structure_filebeat = Filebeat('Structure Prediction') # Changed variable name to structure_filebeat
    epit_filebeat = Filebeat('Epitopes overlapping') # Changed variable name to epit_filebeat
    distances_filebeat = Filebeat('Residues distances') # Changed variable name to distances_filebeat
    sasa_filebeat = Filebeat('SASA') # Changed variable name to sasa_filebeat
    score_function = Integrations('Score function')
    score_filebeat = Filebeat('Score') # Changed variable name to score_filebeat

    fasta_filebeat >> deepmind >> structure_filebeat # Changed variable name to fasta_filebeat, structure_filebeat
    fasta_filebeat >> da # Changed variable name to fasta_filebeat
    db_filebeat >> da >> epit_filebeat >> score_function # Changed variable name to db_filebeat, epit_filebeat
    structure_filebeat >> distance_calc >> distances_filebeat >> score_function # Changed variable name to structure_filebeat, distances_filebeat
    structure_filebeat >> sasa_calc >> sasa_filebeat >> score_function # Changed variable name to structure_filebeat, sasa_filebeat
    score_function >> score_filebeat # Changed variable name to score_filebeat
    centroid_filebeat >> distance_calc # Changed variable name to centroid_filebeat

diag